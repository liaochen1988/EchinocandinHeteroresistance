{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0131bcd-148b-4695-8e6f-9535bcb21fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# imbalance learn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# deepnet \n",
    "sys.path.insert(0, 'ENNS')\n",
    "from dnp2 import DeepNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\"\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc37ce9-29f3-47a8-923c-294de6cd1e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.6\n"
     ]
    }
   ],
   "source": [
    "# NOTE: The ENNS feature selector below might cause segmentation fault in python 3.9.\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f2eee-9bca-4109-ae99-10429abf65ec",
   "metadata": {},
   "source": [
    "## Load genomic features and their corresponding heteroresistance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54367e1-c960-40a2-a276-eb44b34e1d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 6806), (160, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use ALL features (SNV, InDel, CNV)\n",
    "df_X = pd.read_csv('data/Xmatrix_all_features.csv', index_col=0)\n",
    "df_y = pd.read_csv(\"data/Ylabel.csv\", index_col=0).astype(int).loc[df_X.index]\n",
    "df_X.shape, df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f752f1-b937-4748-ab66-afbfb5474763",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# If only SNV is used, unblock the following codes\n",
    "#df_X = pd.read_csv('data/Xmatrix_SNV_only.csv', index_col=0)\n",
    "#df_y = pd.read_csv(\"data/Ylabel.csv\", index_col=0)[['HR']].astype(int).loc[df_X.index]\n",
    "#df_X.shape, df_y.shape\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecad906-9a10-4853-a909-323db06c4190",
   "metadata": {},
   "source": [
    "## Random subsampling validation in the outer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe03615-2385-4786-b86f-092d64b697d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It might take several days to a week to complete over 50 subsampling repeats.\n",
    "# Therefore, I set N to 2 for a quicker run.\n",
    "N = 2\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6139a1-7228-4c15-8fb7-80e67ed49630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteraction</th>\n",
       "      <th>train_set_isolates</th>\n",
       "      <th>test_set_isolates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CDC336,MSK808,E12,E81,MSK1666,E1,MSK2191,MSK24...</td>\n",
       "      <td>E38,MSK844,E80,CDC337,UWM1195,E44,CDC344,MSK24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MSK2413,E36,E12,MSK800,GL28,CDC340,MSK314,MSK2...</td>\n",
       "      <td>E34,E10,E81,CDC336,MSK804,E51,E54,MSK2448,E14,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteraction                                 train_set_isolates  \\\n",
       "0           0  CDC336,MSK808,E12,E81,MSK1666,E1,MSK2191,MSK24...   \n",
       "1           1  MSK2413,E36,E12,MSK800,GL28,CDC340,MSK314,MSK2...   \n",
       "\n",
       "                                   test_set_isolates  \n",
       "0  E38,MSK844,E80,CDC337,UWM1195,E44,CDC344,MSK24...  \n",
       "1  E34,E10,E81,CDC336,MSK804,E51,E54,MSK2448,E14,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# If you want to try the 50 data splits used to generate the figures,\n",
    "# please uncomment the following line of code and ignore the codes in this cell\n",
    "#\n",
    "# df_data_split = pd.read_csv(\"data/train_test_splits.csv\")\n",
    "#\n",
    "###############################################################################\n",
    "train_test_splits = []\n",
    "for iteration in np.arange(0,N):    \n",
    "    df_X_shuffle = deepcopy(df_X.sample(frac=1))\n",
    "    df_y_shuffle = df_y.loc[df_X_shuffle.index]\n",
    "    \n",
    "    # get train and test dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X_shuffle, df_y_shuffle, test_size=0.20, random_state=random_state, stratify=df_y_shuffle.HR)\n",
    "    train_isolates = (',').join(list(X_train.index))\n",
    "    test_isolates = (',').join(list(X_test.index))\n",
    "    \n",
    "    train_test_splits.append([iteration, train_isolates, test_isolates])\n",
    "df_data_split = pd.DataFrame(train_test_splits, columns=['iteraction', 'train_set_isolates','test_set_isolates'])\n",
    "df_data_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d576765-f446-402f-98a0-732d68aef25a",
   "metadata": {},
   "source": [
    "## Define feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e8fcbd-0934-44cf-a214-3702104cac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "class feature_selector_logit(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=10):\n",
    "        self.n_features = n_features\n",
    "        self.selected_features = None\n",
    "    def fit(self, X, y=None):\n",
    "        tmp = []\n",
    "        for f in X.columns:\n",
    "            xk = X[[f]]\n",
    "            yk = y[['HR']]\n",
    "            logit_model=sm.Logit(yk, sm.add_constant(xk))\n",
    "            resk=logit_model.fit(method='bfgs', disp=0)\n",
    "            tmp.append([f, resk.summary2().tables[1].loc[f,'P>|z|']])\n",
    "        df_tmp = pd.DataFrame(tmp, columns=['Feature','Pvalue'])\n",
    "        df_tmp = df_tmp[df_tmp.Pvalue.notnull()]\n",
    "        df_tmp = df_tmp.sort_values('Pvalue')\n",
    "        self.selected_features = list(df_tmp.iloc[:self.n_features].Feature)\n",
    "        return self\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        return X[self.selected_features]\n",
    "\n",
    "# Lasso\n",
    "class feature_selector_lasso(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=10):\n",
    "        self.n_features = n_features\n",
    "        self.selected_features = None\n",
    "    def fit(self, X, y=None):\n",
    "        reg = LassoCV(\n",
    "            cv=3,\n",
    "            random_state=42,\n",
    "            n_alphas=1000,\n",
    "            max_iter=100000,\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        ).fit(X.values, np.ravel(y.values))\n",
    "        df_reg = pd.DataFrame(reg.coef_, index=X.columns, columns=['Coef'])\n",
    "        df_reg = df_reg[df_reg.Coef != 0]\n",
    "        df_reg['AbsCoef'] = np.abs(df_reg['Coef'])\n",
    "        df_reg = df_reg.sort_values('AbsCoef', ascending=False)\n",
    "        \n",
    "        # deal with situation when no feature was selected\n",
    "        if len(df_reg) == 0:\n",
    "            # then randomly selected n_features\n",
    "            self.selected_features = random.sample(X.columns, self.n_features)\n",
    "        else:\n",
    "            if len(df_reg) > self.n_features:\n",
    "                df_reg = df_reg.iloc[:self.n_features,:]\n",
    "                assert len(df_reg) == self.n_features\n",
    "            self.selected_features = list(df_reg.index)\n",
    "        return self\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        return X[self.selected_features]\n",
    "    \n",
    "# ENNS\n",
    "class feature_selector_enns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=10):\n",
    "        self.n_features = n_features\n",
    "        self.selected_features = None\n",
    "    def fit(self, X, y=None):\n",
    "        slc = DeepNet(max_feature=self.n_features)\n",
    "        self.selected_features = [list(X.columns)[idx-1] for idx in slc.train(X, y, return_select=True, verbosity=2)]\n",
    "        return self\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        return X[self.selected_features]\n",
    "    \n",
    "feature_selectors = {\n",
    "    'Logit':feature_selector_logit(),\n",
    "    'Lasso':feature_selector_lasso(),\n",
    "    'ENNS':feature_selector_enns()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb50c74-5633-498f-beba-b4fa52558e6e",
   "metadata": {},
   "source": [
    "## Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0663fa70-d8f6-41fa-b2ea-cee5601e37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=1000, random_state=random_state, class_weight=\"balanced\")\n",
    "xgboost = xgb.XGBClassifier(n_estimators=1000, seed=random_state, objective='binary:logistic')\n",
    "classifiers = {\n",
    "    'RFC':random_forest,\n",
    "    'XGB':xgboost\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda838aa-e1bf-415a-b11d-cd9648426eb1",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbca2e6f-2146-4a15-a255-b2a15d31b46f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration: 0\n",
      "training model (Logit + RFC)...\n",
      "training model (Logit + XGB)...\n",
      "training model (Lasso + RFC)...\n",
      "training model (Lasso + XGB)...\n",
      "training model (ENNS + RFC)...\n",
      "training model (ENNS + XGB)...\n",
      "Done.\n",
      "\n",
      "Current iteration: 1\n",
      "training model (Logit + RFC)...\n",
      "training model (Logit + XGB)...\n",
      "training model (Lasso + RFC)...\n",
      "training model (Lasso + XGB)...\n",
      "training model (ENNS + RFC)...\n",
      "training model (ENNS + XGB)...\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>feature_selector</th>\n",
       "      <th>classification_model</th>\n",
       "      <th>best_model_n_features</th>\n",
       "      <th>selected_features</th>\n",
       "      <th>best_params</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>false_negative_test</th>\n",
       "      <th>false_positive_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>RFC</td>\n",
       "      <td>8</td>\n",
       "      <td>Pattern_2154 (0.4046),Pattern_1139 (0.1552),Pa...</td>\n",
       "      <td>classifier__max_depth:4,classifier__max_featur...</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>E38,E34,E46</td>\n",
       "      <td>MSK800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>XGB</td>\n",
       "      <td>8</td>\n",
       "      <td>Pattern_2154 (0.4361),Pattern_4466 (0.3562),Pa...</td>\n",
       "      <td>classifier__colsample_bytree:0.5,classifier__l...</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>E38,CDC344,E34,E46</td>\n",
       "      <td>MSK800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>RFC</td>\n",
       "      <td>8</td>\n",
       "      <td>Pattern_2154 (0.2486),Pattern_5814 (0.2331),Pa...</td>\n",
       "      <td>classifier__max_depth:2,classifier__max_featur...</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>E38,CDC344,E34,E46</td>\n",
       "      <td>MSK800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>XGB</td>\n",
       "      <td>4</td>\n",
       "      <td>Pattern_2154 (0.5826),Pattern_5513 (0.4174),Pa...</td>\n",
       "      <td>classifier__colsample_bytree:0.5,classifier__l...</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>E38,E34,E46</td>\n",
       "      <td>MSK800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ENNS</td>\n",
       "      <td>RFC</td>\n",
       "      <td>4</td>\n",
       "      <td>Pattern_2154 (0.3976),Pattern_4466 (0.3087),Pa...</td>\n",
       "      <td>classifier__max_depth:2,classifier__max_featur...</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>E38,E34,E46</td>\n",
       "      <td>MSK800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration feature_selector classification_model  best_model_n_features  \\\n",
       "0          0            Logit                  RFC                      8   \n",
       "1          0            Logit                  XGB                      8   \n",
       "2          0            Lasso                  RFC                      8   \n",
       "3          0            Lasso                  XGB                      4   \n",
       "4          0             ENNS                  RFC                      4   \n",
       "\n",
       "                                   selected_features  \\\n",
       "0  Pattern_2154 (0.4046),Pattern_1139 (0.1552),Pa...   \n",
       "1  Pattern_2154 (0.4361),Pattern_4466 (0.3562),Pa...   \n",
       "2  Pattern_2154 (0.2486),Pattern_5814 (0.2331),Pa...   \n",
       "3  Pattern_2154 (0.5826),Pattern_5513 (0.4174),Pa...   \n",
       "4  Pattern_2154 (0.3976),Pattern_4466 (0.3087),Pa...   \n",
       "\n",
       "                                         best_params  accuracy_train  \\\n",
       "0  classifier__max_depth:4,classifier__max_featur...        0.867188   \n",
       "1  classifier__colsample_bytree:0.5,classifier__l...        0.859375   \n",
       "2  classifier__max_depth:2,classifier__max_featur...        0.867188   \n",
       "3  classifier__colsample_bytree:0.5,classifier__l...        0.843750   \n",
       "4  classifier__max_depth:2,classifier__max_featur...        0.851562   \n",
       "\n",
       "   precision_train  recall_train  f1_train  accuracy_test  precision_test  \\\n",
       "0         0.800000      0.780488  0.790123        0.87500        0.875000   \n",
       "1         0.828571      0.707317  0.763158        0.84375        0.857143   \n",
       "2         0.875000      0.682927  0.767123        0.84375        0.857143   \n",
       "3         0.783784      0.707317  0.743590        0.87500        0.875000   \n",
       "4         0.775000      0.756098  0.765432        0.87500        0.875000   \n",
       "\n",
       "   recall_test   f1_test false_negative_test false_positive_test  \n",
       "0          0.7  0.777778         E38,E34,E46              MSK800  \n",
       "1          0.6  0.705882  E38,CDC344,E34,E46              MSK800  \n",
       "2          0.6  0.705882  E38,CDC344,E34,E46              MSK800  \n",
       "3          0.7  0.777778         E38,E34,E46              MSK800  \n",
       "4          0.7  0.777778         E38,E34,E46              MSK800  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = []\n",
    "for iteration in np.arange(0,N):\n",
    "    print('Current iteration:', iteration)\n",
    "    \n",
    "    # get the outer training and test dataset for each iteration\n",
    "    train_isolates = df_data_split.loc[iteration,'train_set_isolates'].split(',')\n",
    "    test_isolates = df_data_split.loc[iteration,'test_set_isolates'].split(',')\n",
    "    X_train = deepcopy(df_X.loc[train_isolates])\n",
    "    X_test = deepcopy(df_X.loc[test_isolates])\n",
    "    y_train = deepcopy(df_y.loc[train_isolates])\n",
    "    y_test = deepcopy(df_y.loc[test_isolates])\n",
    "\n",
    "    #####################################################################\n",
    "    # If using undersampling or oversampling, unblock the following codes\n",
    "    # \n",
    "    # oversampling\n",
    "    # smote = SMOTE(random_state=random_state)\n",
    "    # X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    #\n",
    "    # undersampling\n",
    "    # rus = RandomUnderSampler(random_state=random_state)\n",
    "    # X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "    #####################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    # If shuffling heteroresistance labels, unblock the following codes\n",
    "    # \n",
    "    # y_train['HR'] = y_train['HR'].sample(frac=1).values\n",
    "    ###################################################################\n",
    "    \n",
    "    # use the outer training dataset for feature selection and hyperparameter tuning\n",
    "    # use the outer test dataset for model evaluation\n",
    "    for feature_selector in ['Logit','Lasso','ENNS']:\n",
    "        for classifier in ['RFC','XGB']:\n",
    "            print('training model (%s + %s)...'%(feature_selector, classifier))\n",
    "            \n",
    "            if classifier=='RFC':\n",
    "                parameters = {\n",
    "                    'feature_selector__n_features':[2,4,6,8,10],\n",
    "                    'classifier__max_features':['sqrt',None],\n",
    "                    'classifier__max_depth':[2,4,6],\n",
    "                    'classifier__max_samples':[0.5,0.75,1.0]\n",
    "                }\n",
    "            elif classifier=='XGB':\n",
    "                parameters = {\n",
    "                    'feature_selector__n_features':[2,4,6,8,10],\n",
    "                    'classifier__colsample_bytree':[0.5,0.75,1.0],\n",
    "                    'classifier__max_depth':[2,4,6],\n",
    "                    'classifier__learning_rate':[0.3,0.1,0.03]\n",
    "                }\n",
    "\n",
    "            # create pipeline\n",
    "            scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "            thresholder = VarianceThreshold().set_output(transform=\"pandas\")\n",
    "            pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\"scaler\", scaler), \n",
    "                    (\"thresholder\", thresholder),\n",
    "                    (\"feature_selector\", feature_selectors[feature_selector]), \n",
    "                    (\"classifier\", classifiers[classifier])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # run grid search for model training\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                CV = GridSearchCV(pipeline, parameters, scoring='f1', cv=StratifiedKFold(n_splits=5), n_jobs=-1, verbose=0)\n",
    "                CV.fit(X_train,y_train)\n",
    "            \n",
    "            # compute training scores\n",
    "            final_model = CV.best_estimator_\n",
    "            y_pred = CV.predict(X_train)\n",
    "            accuracy_train = accuracy_score(y_true=y_train, y_pred=y_pred)\n",
    "            precision_train = precision_score(y_true=y_train, y_pred=y_pred)\n",
    "            recall_train = recall_score(y_true=y_train, y_pred=y_pred)\n",
    "            f1_train = f1_score(y_true=y_train, y_pred=y_pred)\n",
    "\n",
    "            # compute test scores\n",
    "            y_pred = CV.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "            precision_test = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "            recall_test = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "            f1_test = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "            FN_test = []\n",
    "            FP_test = []\n",
    "            for ti,y1,y2 in zip(list(X_test.index),list(y_pred),list(y_test.HR)):\n",
    "                if y1 == 0 and y2 == 1:\n",
    "                    FN_test.append(ti)\n",
    "                if y1 == 1 and y2 == 0:\n",
    "                    FP_test.append(ti)\n",
    "            \n",
    "            # get selected features\n",
    "            X_train2 = scaler.fit_transform(X_train)\n",
    "            X_train2 = thresholder.fit_transform(X_train2)\n",
    "            n_features = CV.best_params_['feature_selector__n_features']\n",
    "            selected_features = CV.best_estimator_.steps[-2][1].selected_features\n",
    "            feature_importance = list(CV.best_estimator_.steps[-1][1].feature_importances_)\n",
    "            selected_features = [\"%s (%2.4f)\"%(x,y) for y, x in sorted(zip(feature_importance, selected_features), reverse=True)] \n",
    "\n",
    "            # get best parameters\n",
    "            bestp = ''\n",
    "            for k,v in CV.best_params_.items():\n",
    "                bestp += '%s:%s,'%(k,v)\n",
    "            bestp = bestp.rstrip(',')\n",
    "                \n",
    "            # save to results\n",
    "            evaluation.append(\n",
    "                [iteration, feature_selector, classifier, n_features, (',').join(selected_features), bestp,\n",
    "                 accuracy_train, precision_train, recall_train, f1_train,\n",
    "                 accuracy_test, precision_test, recall_test, f1_test,\n",
    "                 (',').join(FN_test), (',').join(FP_test)]\n",
    "            )\n",
    "\n",
    "    print('Done.')\n",
    "    print()\n",
    "    \n",
    "df_eval = pd.DataFrame(evaluation, \n",
    "                       columns=[\n",
    "                           'iteration','feature_selector','classification_model','best_model_n_features','selected_features','best_params',\n",
    "                           'accuracy_train','precision_train','recall_train','f1_train',\n",
    "                           'accuracy_test','precision_test','recall_test','f1_test',\n",
    "                           'false_negative_test','false_positive_test']\n",
    "                      )\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16beb7e9-7d08-4c6f-8fc1-e26cdb714aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
